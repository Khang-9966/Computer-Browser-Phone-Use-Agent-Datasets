# Awesome GUI Agent Datasets for Computer and Phone Use

A curated list of datasets for training GUI agents—AI systems that automate interactions with graphical user interfaces on computers, phones, and browsers. These datasets support tasks like clicking, typing, and navigating visual elements, making them essential for researchers and developers advancing AI agent training and GUI automation. Sorted by year (most recent first), each entry includes the dataset name, a brief description, and a URL where available.

---

## 2025

- **LearnGUI**  
  - *Description*: A dataset for studying illustration-based learning in mobile GUI agents, enhancing performance in unseen scenarios.  
  - *URL*: [https://huggingface.co/datasets/lgy0404/LearnGUI](https://huggingface.co/datasets/lgy0404/LearnGUI)

- **AndroidInteraction**  
  - *Description*: Focuses on user interaction needs and notifications in phone UI automation, enabling agent-initiated interactions.  
  - *URL*: [https://arxiv.org/abs/2503.19537](https://arxiv.org/abs/2503.19537)

- **WorldGUI**  
  - *Description*: An interactive benchmark for desktop GUI automation, supporting tasks across multiple applications from any starting point.  
  - *URL*: [https://github.com/showlab/WorldGUI](https://github.com/showlab/WorldGUI)

- **DeskVision**  
  - *Description*: Large-scale desktop region captioning dataset for advanced GUI agents, improving visual element understanding.  
  - *URL*: [https://arxiv.org/abs/2503.11170](https://arxiv.org/abs/2503.11170)

- **GUI-Lasagne**  
  - *Description*: Multi-level, large-scale dataset for training agents like SpiritSight, focusing on GUI understanding and grounding.  
  - *URL*: [https://arxiv.org/abs/2503.03196](https://arxiv.org/abs/2503.03196)

- **TongUI / GUI-Net**  
  - *Description*: Builds generalized GUI agents by learning from multimodal web tutorials across multiple OS.  
  - *URL*: [https://tongui-agent.github.io/](https://tongui-agent.github.io/)

- **ScreenSpot-Pro**  
  - *Description*: Benchmark for GUI grounding in high-resolution professional environments, ideal for multimodal LLMs.  
  - *URL*: [https://huggingface.co/datasets/Voxel51/ScreenSpot-Pro](https://huggingface.co/datasets/Voxel51/ScreenSpot-Pro)

- **WebGames**  
  - *Description*: A dataset for training agents to play web-based games, focusing on interactive GUI tasks.  
  - *URL*: https://github.com/convergence-ai/webgames

---

## 2024

- **DroidCall**  
  - *Description*: Dataset for training LLMs to invoke Android intents accurately, boosting mobile agent capabilities.  
  - *URL*: [https://github.com/UbiquitousLearning/DroidCall](https://github.com/UbiquitousLearning/DroidCall)

- **MobileViews**  
  - *Description*: Large-scale mobile GUI dataset with over 600,000 screenshot-view hierarchy pairs from 20,000+ Android apps.  
  - *URL*: [https://huggingface.co/datasets/mllmTeam/MobileViews](https://huggingface.co/datasets/mllmTeam/MobileViews)

- **AMEX (Android Multi-annotation EXpo)**  
  - *Description*: Over 104,000 high-resolution screenshots from 110 popular mobile apps with detailed annotations.  
  - *URL*: [https://huggingface.co/datasets/Yuxiang007/AMEX](https://huggingface.co/datasets/Yuxiang007/AMEX)

- **AndroidControl**  
  - *Description*: 15,283 demonstrations of daily tasks across 833 Android apps, exploring data scale effects.  
  - *URL*: [https://huggingface.co/datasets/HarrytheOrange/parsed_AndroidControl](https://huggingface.co/datasets/HarrytheOrange/parsed_AndroidControl)

- **B-MoCA**  
  - *Description*: Benchmark for evaluating mobile control agents across diverse device configurations.  
  - *URL*: [https://github.com/gimme1dollar/b-moca](https://github.com/gimme1dollar/b-moca)

- **MobileAgentBench**  
  - *Description*: User-friendly benchmark with 100 tasks across 10 open-source apps for testing mobile LLM agents.  
  - *URL*: [https://MobileAgentBench.github.io](https://MobileAgentBench.github.io)

- **Mobile3M**  
  - *Description*: A dataset for mobile app understanding with 3 million examples for training GUI agents.  
  - *URL*: https://huggingface.co/datasets/xwk123/Mobile3M

- **OmniACT**  
  - *Description*: Dataset for multimodal generalist agents performing tasks on desktop and web interfaces.  
  - *URL*: [https://arxiv.org/abs/2402.17553](https://arxiv.org/abs/2402.17553)

- **VisualWebArena**  
  - *Description*: A dataset for training agents to interact with web interfaces using visual inputs.  
  - *URL*: https://github.com/web-arena-x/visualwebarena

- **WebCanvas**  
  - *Description*: A dataset for training agents to interact with web-based creative tools like drawing apps.  
  - *URL*: https://github.com/iMeanAI/WebCanvas

- **VisualWebBench**  
  - *Description*: A benchmark for evaluating visual web interaction tasks.  
  - *URL*: https://github.com/VisualWebBench

- **Cradle**  
  - *Description*: A dataset for training GUI agents to perform tasks in simulated environments.  
  - *URL*: https://github.com/prodaft/cradle/

- **CRAB**  
  - *Description*: Cross-environment benchmark for multimodal agents, supporting Ubuntu and Android tasks.  
  - *URL*: [https://crab.camel-ai.org/](https://crab.camel-ai.org/)

- **GUI-World**  
  - *Description*: Comprehensive GUI dataset with over 12K videos and 100K queries for evaluating multimodal LLM-based agents.  
  - *URL*: [https://gui-world.github.io/](https://gui-world.github.io/)

- **AgentStudio (GroundUI)**  
  - *Description*: Includes 18,000 instruction-screenshot pairs for evaluating GUI interactions in a versatile toolkit.  
  - *URL*: [https://github.com/agenticevangelist/agent-studio](https://github.com/agenticevangelist/agent-studio)

- **AgentStudio (IDMBench)**  
  - *Description*: Dataset for evaluating multi-step agent trajectories in GUI interactions.  
  - *URL*: [https://github.com/agenticevangelist/agent-studio](https://github.com/agenticevangelist/agent-studio)

- **AgentStudio (CriticBench)**  
  - *Description*: Dataset for assessing LLM-based agents’ reasoning and critique capabilities in GUI contexts.  
  - *URL*: [https://github.com/agenticevangelist/agent-studio](https://github.com/agenticevangelist/agent-studio)

- **GUICourse (GUIEnv)**  
  - *Description*: Features 10M page-caption pairs for training vision-based GUI agents across web and mobile.  
  - *URL*: [https://github.com/yiye3/GUICourse](https://github.com/yiye3/GUICourse)

- **GUICourse (GUIAct)**  
  - *Description*: Contains 67K single-step and 15K multi-step instructions for GUI actions.  
  - *URL*: [https://github.com/yiye3/GUICourse](https://github.com/yiye3/GUICourse)

- **GUICourse (GUIChat)**  
  - *Description*: Offers 44K single-turn QAs and 6K multi-turn dialogues for GUI interactions.  
  - *URL*: [https://github.com/yiye3/GUICourse](https://github.com/yiye3/GUICourse)

- **UEyes**  
  - *Description*: Eye-tracking dataset for understanding visual saliency across various user interfaces.  
  - *URL*: [https://github.com/YueJiang-nj/UEyes-CHI2023](https://github.com/YueJiang-nj/UEyes-CHI2023)

---

## 2023

- **Android in the Wild (AITW)**  
  - *Description*: Large-scale dataset with 715,142 episodes for Android device control across 30,378 unique instructions.  
  - *URL*: [https://github.com/google-research/google-research/tree/master/android_in_the_wild](https://github.com/google-research/google-research/tree/master/android_in_the_wild)

- **AutoUI**  
  - *Description*: Leverages AITW to evaluate Auto-GUI, an LLM-based task automation system for Android.  
  - *URL*: [https://github.com/cooelf/Auto-GUI](https://github.com/cooelf/Auto-GUI)

- **GUI Odyssey**  
  - *Description*: A dataset for evaluating GUI agents across diverse tasks and environments.  
  - *URL*: https://github.com/OpenGVLab/GUI-Odyssey

- **AndroidEnv**  
  - *Description*: A simulated environment for testing Android GUI agents.  
  - *URL*: https://github.com/deepmind/android_env

- **Mobile-Env**  
  - *Description*: A dataset for training agents to interact with mobile apps in simulated environments.  
  - *URL*: https://github.com/X-LANCE/Mobile-Env

- **AndroidWorld**  
  - *Description*: An environment for building and benchmarking autonomous computer control agents.  
  - *URL*: [https://github.com/MetaGLAD/AndroidWorld](https://github.com/MetaGLAD/AndroidWorld)

- **RICOSCA**  
  - *Description*: A dataset for Android app security analysis.  
  - *URL*: https://paperswithcode.com/dataset/ricosca

- **ANDROIDHOWTO**  
  - *Description*: A dataset for training agents to follow step-by-step instructions on Android devices.  
  - *URL*: https://github.com/debymf/generating_android_howto

- **PixelHelp**  
  - *Description*: Features 187 multi-step instructions for common tasks on Google Pixel phones.  
  - *URL*: [https://paperswithcode.com/dataset/pixelhelp](https://paperswithcode.com/dataset/pixelhelp)

- **UGIF**  
  - *Description*: A dataset for understanding user interactions with graphical interfaces.  
  - *URL*: https://paperswithcode.com/dataset/ugif

- **META-GUI**  
  - *Description*: Benchmark for GUI-based task-oriented dialogue systems with 1,125 dialogues across six domains.  
  - *URL*: [https://x-lance.github.io/META-GUI-Leaderboard/](https://x-lance.github.io/META-GUI-Leaderboard/)

- **Mind2Web**  
  - *Description*: A dataset for training agents to interact with web pages using natural language.  
  - *URL*: https://osu-nlp-group.github.io/Mind2Web/

- **WebArena**  
  - *Description*: A dataset for training agents to perform tasks on web pages.  
  - *URL*: https://webarena.dev/

- **WebVoyager**  
  - *Description*: A dataset for training agents to navigate and interact with web environments.  
  - *URL*: https://arxiv.org/abs/2401.13919

- **Synapse**  
  - *Description*: A dataset for training agents to perform tasks across multiple applications.  
  - *URL*: https://ltzheng.github.io/Synapse

- **ASSISTGUI**  
  - *Description*: A dataset for evaluating GUI agents in assistive technology contexts.  
  - *URL*: https://showlab.github.io/assistgui/

- **ScreenAgent**  
  - *Description*: A dataset for training agents to interact with screen-based interfaces.  
  - *URL*: https://github.com/niuzaisheng/ScreenAgent

---

## 2022

- **WebShop**  
  - *Description*: Dataset for training autonomous agents in online shopping with 1.18 million real-world products.  
  - *URL*: [https://webshop-pnlp.github.io](https://webshop-pnlp.github.io)

- **UIBert (AppSim & RefExp)**  
  - *Description*: A dataset for understanding and generating UI descriptions.  
  - *URL*: https://github.com/google-research-datasets/uibert

---

## 2021

- **Screen Annotation**  
  - *Description*: Dataset for generating concise language descriptions of mobile screens.  
  - *URL*: [https://github.com/google-research-datasets/screen2words](https://github.com/google-research-datasets/screen2words)

- **MoTIF (Mobile app Tasks with Iterative Feedback)**  
  - *Description*: A dataset for training agents to perform tasks on mobile apps with user feedback.  
  - *URL*: https://vigilworkshop.github.io/static/papers-2021/26.pdf

---

## 2018

- **RICO**  
  - *Description*: Contains 72,000 unique Android app UIs, a foundational dataset for mobile GUI research.  
  - *URL*: [https://www.kaggle.com/datasets/onurgunes1993/rico-dataset](https://www.kaggle.com/datasets/onurgunes1993/rico-dataset)

---

This Awesome List is a comprehensive resource for GUI agent datasets, covering mobile, desktop, and web environments. Contributions are welcome to keep it updated with the latest advancements in computer interaction datasets!
